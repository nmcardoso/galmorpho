{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "splus_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1AZ581kRn-dsuPaP-9xt3ys9A5ZCXVaA1",
      "authorship_tag": "ABX9TyPqxZk/+ldjF0r0hiGr43EO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmcardoso/splus-model/blob/master/splus_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vivABYTN239V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x \n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "import os\n",
        "import glob\n",
        "import multiprocessing as mp\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras import utils\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.applications import VGG16\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from progressbar import progressbar\n",
        "\n",
        "!pip3 install git+https://github.com/nmcardoso/fitsbook-python\n",
        "import fitsbook as fb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqLHp_vx9e2V",
        "colab_type": "code",
        "outputId": "53a2642a-c5fc-42e3-8435-cd0864b17e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Reprodutibilidade\n",
        "# https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = '12'\n",
        "np.random.seed(123)\n",
        "random.seed(1234)\n",
        "tf.set_random_seed(12345)\n",
        "\n",
        "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, \n",
        "#                               inter_op_parallelism_threads=1)\n",
        "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)\n",
        "\n",
        "print('Sementes Plantadas!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sementes Plantadas!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVf7HjPhJYsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/drive/'My Drive'/datasets/stamps_scaled.zip -d dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkaeAapaNCyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -zxvf /content/drive/'My Drive'/datasets/dataset.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faZlo4FERwdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/'My Drive'/datasets/stamps_scaled.csv /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKouK0TO1odD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NpySequence(utils.Sequence):\n",
        "  \"\"\"Generate data for Keras\"\"\"\n",
        "  def __init__(self, files, labels, classes, image_size=(256, 256), channels=3, batch_size=32):\n",
        "    self.files = files\n",
        "    self.labels = self.__to_categorical(labels, classes)\n",
        "    self.image_size = image_size\n",
        "    self.channels = channels\n",
        "    self.batch_size = batch_size\n",
        "    self.indexes = [i for i in range(len(files))]\n",
        "    np.random.shuffle(self.indexes)\n",
        "    # self.on_epoch_end()\n",
        "  \n",
        "  def __len__(self):\n",
        "    \"\"\"The number of batches per epoch\"\"\"\n",
        "    return int(np.floor(len(self.files) / self.batch_size))\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"Generate one batch of data\"\"\"\n",
        "    partition = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    X, Y = self.__data_generation(partition)\n",
        "    return X, Y\n",
        "  \n",
        "  def on_epoch_end(self):\n",
        "    \"\"\"Shuffle files list and remap labels\"\"\"\n",
        "    np.random.shuffle(self.indexes)\n",
        "    \n",
        "  def __to_categorical(self, labels, classes):\n",
        "    \"\"\"Labels to numbers\"\"\"\n",
        "    classes_dict = {c:i for i,c in enumerate(classes)}\n",
        "    return [classes_dict[l] for l in labels]\n",
        "\n",
        "  def __data_generation(self, partition):\n",
        "    \"\"\"Load npy file and associate with a label\"\"\"\n",
        "    X = np.empty((self.batch_size, *self.image_size, self.channels))\n",
        "    Y = np.empty((self.batch_size,), dtype=int)\n",
        "\n",
        "    for i, index in enumerate(partition):\n",
        "      X[i,] = np.load(self.files[index])\n",
        "      Y[i] = self.labels[index]\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ghBzSbF9fpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess():\n",
        "  global train_generator, test_generator, val_generator\n",
        "  df = pd.read_csv('/content/stamps_scaled.csv')\n",
        "  E = df[df.CLASS == 'E']\n",
        "  S = df[df.CLASS == 'S']\n",
        "\n",
        "  # train_df = pd.concat([E[0:3127], S[0:951]])\n",
        "  train_df = pd.concat([E[0:250], S[0:250]])\n",
        "  train_X = [f'/content/dataset/{f}.npy' for f in train_df.ID.tolist()]\n",
        "  train_Y = train_df.CLASS.tolist()\n",
        "\n",
        "  # val_df = pd.concat([E[3128:5004], S[952:1522]])\n",
        "  val_df = pd.concat([E[251:425], S[251:425]])\n",
        "  val_X = [f'/content/dataset/{f}.npy' for f in val_df.ID.tolist()]\n",
        "  val_Y = val_df.CLASS.tolist()\n",
        "\n",
        "  # test_df = pd.concat([E[5005:], S[1523:]])\n",
        "  test_df = pd.concat([E[426:550], S[426:550]])\n",
        "  test_X = [f'/content/dataset/{f}.npy' for f in test_df.ID.tolist()]\n",
        "  test_Y = test_df.CLASS.tolist()\n",
        "\n",
        "  train_generator = NpySequence(train_X, train_Y, ['E', 'S'])\n",
        "  val_generator = NpySequence(val_X, val_Y, ['E', 'S'])\n",
        "  test_generator = NpySequence(test_X, test_Y, ['E', 'S'])\n",
        "\n",
        "def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
        "  # 1x1 conv\n",
        "  conv1 = layers.Conv2D(f1, (1, 1), padding='same', activation='relu')(layer_in)\n",
        "\n",
        "  # 3x3 conv\n",
        "  conv3 = layers.Conv2D(f2_in, (1, 1), padding='same', activation='relu')(layer_in)\n",
        "  conv3 = layers.Conv2D(f2_out, (3, 3), padding='same', activation='relu')(layer_in)\n",
        "\n",
        "  # 5x5 conv\n",
        "  conv5 = layers.Conv2D(f3_in, (1, 1), padding='same', activation='relu')(layer_in)\n",
        "  conv5 = layers.Conv2D(f3_out, (5, 5), padding='same', activation='relu')(conv5)\n",
        "\n",
        "  # 3x3 max pooling\n",
        "  pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(layer_in)\n",
        "  pool = layers.Conv2D(f4_out, (1, 1), padding='same', activation='relu')(pool)\n",
        "\n",
        "  # concatenate filters, assumes filters/channels last\n",
        "  layer_out = layers.concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
        "  return layer_out\n",
        "\n",
        "def compile_inception_model(image_size):\n",
        "  input_layer = layers.Input(shape=image_size + (3,))\n",
        "  conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "  pool1 = layers.MaxPool2D((2, 2))(conv1)\n",
        "  conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "  pool2 = layers.MaxPool2D((2, 2))(conv2)\n",
        "  iblock1 = inception_module(input_layer, 32, 48, 64, 8, 16, 16)\n",
        "  iblock2 = inception_module(iblock1, 64, 48, 96, 16, 48, 32)\n",
        "  flatten = layers.Flatten()(iblock2)\n",
        "  dense1 = layers.Dense(1024, activation='relu')(flatten)\n",
        "  dropout1 = layers.Dropout(.3)(dense1)\n",
        "  dense2 = layers.Dense(512, activation='relu')(dropout1)\n",
        "  dropout2 = layers.Dropout(.3)(dense2)\n",
        "  dense3 = layers.Dense(256, activation='relu')(dropout2)\n",
        "  dropout3 = layers.Dropout(.3)(dense3)\n",
        "  output = layers.Dense(1, activation='sigmoid')(dropout3)\n",
        "  model = models.Model(inputs=input_layer, outputs=output)\n",
        "  model.name = 'splus_inception'\n",
        "  utils.plot_model(model, to_file='model.png')\n",
        "  model.compile(optimizer=optimizers.RMSprop(lr=5e-5),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "def compile_model(image_size):\n",
        "  model = models.Sequential()\n",
        "  model.name = 'splus_convolutional'\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size + (3,))))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer=optimizers.RMSprop(lr=5e-5),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "def fit(model, epochs=1):\n",
        "  global history, train_generator, val_generator\n",
        "  history = model.fit_generator(\n",
        "      train_generator,\n",
        "      # steps_per_epoch=80,\n",
        "      # validation_steps=30,\n",
        "      epochs=epochs,\n",
        "      validation_data=val_generator,\n",
        "      callbacks=[fb.callbacks.FitsbookCallback()],\n",
        "      # use_multiprocessing=True,\n",
        "      # workers=2\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm3MY-kw29F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess()\n",
        "m = compile_inception_model((256, 256))\n",
        "fit(m, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}