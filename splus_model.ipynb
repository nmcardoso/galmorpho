{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "splus_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1AZ581kRn-dsuPaP-9xt3ys9A5ZCXVaA1",
      "authorship_tag": "ABX9TyOAfqth/LWi5F0i3ReHWk2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmcardoso/splus-model/blob/master/splus_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vivABYTN239V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x \n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "import os\n",
        "import glob\n",
        "import multiprocessing as mp\n",
        "import shutil\n",
        "\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras import utils\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.applications import VGG16\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from progressbar import progressbar\n",
        "\n",
        "!pip3 install git+https://github.com/nmcardoso/fitsbook-python\n",
        "import fitsbook as fb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqLHp_vx9e2V",
        "colab_type": "code",
        "outputId": "5217829e-574e-4689-e8d6-661e689df64c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Reprodutibilidade\n",
        "# https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = '12'\n",
        "np.random.seed(123)\n",
        "random.seed(1234)\n",
        "tf.set_random_seed(12345)\n",
        "\n",
        "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, \n",
        "#                               inter_op_parallelism_threads=1)\n",
        "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)\n",
        "\n",
        "print('Sementes Plantadas!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sementes Plantadas!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVf7HjPhJYsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/drive/'My Drive'/datasets/stamps_scaled.zip -d dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkaeAapaNCyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -zxvf /content/drive/'My Drive'/datasets/dataset.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKouK0TO1odD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NpySequence(utils.Sequence):\n",
        "  \"\"\"Generate data for Keras\"\"\"\n",
        "  def __init__(self, path, image_size=(256, 256), channels=3, batch_size=32, shuffle=True):\n",
        "    self.path = path\n",
        "    self.image_size = image_size\n",
        "    self.channels = channels\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = shuffle\n",
        "    self.files = glob.glob(os.path.join(self.path, '*/*.npy'))\n",
        "    np.random.shuffle(self.files)\n",
        "    self.labels_map = self.__get_labels_map()\n",
        "    # self.on_epoch_end()\n",
        "  \n",
        "  def __len__(self):\n",
        "    \"\"\"The number of batches per epoch\"\"\"\n",
        "    return int(np.floor(len(self.files) / self.batch_size))\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"Generate one batch of data\"\"\"\n",
        "    partition = self.files[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    X, Y = self.__data_generation(partition)\n",
        "    return X, Y\n",
        "  \n",
        "  def on_epoch_end(self):\n",
        "    \"\"\"Shuffle files list and remap labels\"\"\"\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.files)\n",
        "    self.labels_map = self.__get_labels_map()\n",
        "    \n",
        "  def __get_labels_map(self):\n",
        "    \"\"\"Create labels dict from dir names\"\"\"\n",
        "    labels = [name for name in os.listdir(self.path) if os.path.isdir(os.path.join(self.path, name)) and name[0] != '.']\n",
        "    labels.sort()\n",
        "    return {l:i for i,l in enumerate(labels)}\n",
        "\n",
        "  def __data_generation(self, partition):\n",
        "    \"\"\"Load npy file and associate with a label\"\"\"\n",
        "    X = np.empty((self.batch_size, *self.image_size, self.channels))\n",
        "    Y = np.empty((self.batch_size,), dtype=int)\n",
        "\n",
        "    for i, file_path in enumerate(partition):\n",
        "      X[i,] = np.load(file_path)\n",
        "      Y[i] = self.labels_map[file_path.split('/')[-2]]\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ghBzSbF9fpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess():\n",
        "  global train_generator, test_generator, val_generator\n",
        "  train_generator = NpySequence('/content/dataset/train')\n",
        "  val_generator = NpySequence('/content/dataset/val')\n",
        "\n",
        "def compile_model(image_size):\n",
        "  global model\n",
        "  model = models.Sequential()\n",
        "  model.name = 'sdss_convolutional'\n",
        "  model.add(layers.Conv2D(256, (3, 3), activation='relu', input_shape=(image_size + (3,))))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer=optimizers.RMSprop(lr=5e-5),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "\n",
        "def fit(epochs=1):\n",
        "  global model, history, train_generator, val_generator\n",
        "  history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=80,\n",
        "      validation_steps=30,\n",
        "      epochs=epochs,\n",
        "      validation_data=val_generator,\n",
        "      callbacks=[fb.callbacks.FitsbookCallback()],\n",
        "      use_multiprocessing=True,\n",
        "      workers=4\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm3MY-kw29F0",
        "colab_type": "code",
        "outputId": "ef51f73f-760a-465d-dc87-bc68f397c444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "preprocess()\n",
        "compile_model((256, 256))\n",
        "fit(300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Fitsbook]: Monitoring this training in real time https://natan.ninja/#/stats/31\n",
            "Epoch 1/300\n",
            "80/80 [==============================] - 159s 2s/step - loss: 0.5851 - acc: 0.7684 - val_loss: 0.5576 - val_acc: 0.7594\n",
            "Epoch 2/300\n",
            "46/80 [================>.............] - ETA: 47s - loss: 0.5676 - acc: 0.7575Epoch 1/300\n",
            "80/80 [==============================] - 137s 2s/step - loss: 0.5697 - acc: 0.7539 - val_loss: 0.5507 - val_acc: 0.7594\n",
            "Epoch 3/300\n",
            "79/80 [============================>.] - ETA: 1s - loss: 0.5452 - acc: 0.7694Epoch 1/300\n",
            "80/80 [==============================] - 152s 2s/step - loss: 0.5433 - acc: 0.7707 - val_loss: 0.5275 - val_acc: 0.7792\n",
            "Epoch 4/300\n",
            "80/80 [==============================] - 146s 2s/step - loss: 0.5462 - acc: 0.7695 - val_loss: 0.5527 - val_acc: 0.7542\n",
            "Epoch 5/300\n",
            "80/80 [==============================] - 138s 2s/step - loss: 0.5453 - acc: 0.7648 - val_loss: 0.5299 - val_acc: 0.7750\n",
            "Epoch 6/300\n",
            "80/80 [==============================] - 151s 2s/step - loss: 0.5290 - acc: 0.7680 - val_loss: 0.5123 - val_acc: 0.7802\n",
            "Epoch 7/300\n",
            "80/80 [==============================] - 142s 2s/step - loss: 0.5150 - acc: 0.7785 - val_loss: 0.5473 - val_acc: 0.7479\n",
            "Epoch 8/300\n",
            "80/80 [==============================] - 142s 2s/step - loss: 0.5204 - acc: 0.7652 - val_loss: 0.5313 - val_acc: 0.7635\n",
            "Epoch 9/300\n",
            "80/80 [==============================] - 151s 2s/step - loss: 0.5183 - acc: 0.7574 - val_loss: 0.5142 - val_acc: 0.7740\n",
            "Epoch 10/300\n",
            "80/80 [==============================] - 138s 2s/step - loss: 0.5061 - acc: 0.7609 - val_loss: 0.5078 - val_acc: 0.7719\n",
            "Epoch 11/300\n",
            "80/80 [==============================] - 150s 2s/step - loss: 0.4812 - acc: 0.7773 - val_loss: 0.4944 - val_acc: 0.7729\n",
            "Epoch 12/300\n",
            "80/80 [==============================] - 152s 2s/step - loss: 0.4905 - acc: 0.7637 - val_loss: 0.5067 - val_acc: 0.7646\n",
            "Epoch 13/300\n",
            "80/80 [==============================] - 137s 2s/step - loss: 0.4864 - acc: 0.7684 - val_loss: 0.5036 - val_acc: 0.7615\n",
            "Epoch 14/300\n",
            "80/80 [==============================] - 150s 2s/step - loss: 0.4791 - acc: 0.7648 - val_loss: 0.5258 - val_acc: 0.7823\n",
            "Epoch 15/300\n",
            "80/80 [==============================] - 145s 2s/step - loss: 0.4725 - acc: 0.7758 - val_loss: 0.4884 - val_acc: 0.7604\n",
            "Epoch 16/300\n",
            "80/80 [==============================] - 138s 2s/step - loss: 0.4813 - acc: 0.7582 - val_loss: 0.4954 - val_acc: 0.7688\n",
            "Epoch 17/300\n",
            "80/80 [==============================] - 154s 2s/step - loss: 0.4763 - acc: 0.7652 - val_loss: 0.4944 - val_acc: 0.7917\n",
            "Epoch 18/300\n",
            "80/80 [==============================] - 136s 2s/step - loss: 0.4701 - acc: 0.7590 - val_loss: 0.5315 - val_acc: 0.7823\n",
            "Epoch 19/300\n",
            "80/80 [==============================] - 141s 2s/step - loss: 0.4570 - acc: 0.7797 - val_loss: 0.4848 - val_acc: 0.7917\n",
            "Epoch 20/300\n",
            "80/80 [==============================] - 159s 2s/step - loss: 0.4657 - acc: 0.7687 - val_loss: 0.5119 - val_acc: 0.7792\n",
            "Epoch 21/300\n",
            "80/80 [==============================] - 137s 2s/step - loss: 0.4490 - acc: 0.7777 - val_loss: 0.4809 - val_acc: 0.8052\n",
            "Epoch 22/300\n",
            "80/80 [==============================] - 151s 2s/step - loss: 0.4561 - acc: 0.7820 - val_loss: 0.5122 - val_acc: 0.7812\n",
            "Epoch 23/300\n",
            "80/80 [==============================] - 146s 2s/step - loss: 0.4511 - acc: 0.7902 - val_loss: 0.5067 - val_acc: 0.7740\n",
            "Epoch 24/300\n",
            "80/80 [==============================] - 136s 2s/step - loss: 0.4510 - acc: 0.7941 - val_loss: 0.4919 - val_acc: 0.8146\n",
            "Epoch 25/300\n",
            "80/80 [==============================] - 152s 2s/step - loss: 0.4661 - acc: 0.7859 - val_loss: 0.4834 - val_acc: 0.7781\n",
            "Epoch 26/300\n",
            "80/80 [==============================] - 139s 2s/step - loss: 0.4383 - acc: 0.8016 - val_loss: 0.4712 - val_acc: 0.8104\n",
            "Epoch 27/300\n",
            "80/80 [==============================] - 146s 2s/step - loss: 0.4484 - acc: 0.8004 - val_loss: 0.5035 - val_acc: 0.7927\n",
            "Epoch 28/300\n",
            "80/80 [==============================] - 150s 2s/step - loss: 0.4331 - acc: 0.8035 - val_loss: 0.4885 - val_acc: 0.7792\n",
            "Epoch 29/300\n",
            "80/80 [==============================] - 137s 2s/step - loss: 0.4313 - acc: 0.8047 - val_loss: 0.5098 - val_acc: 0.7792\n",
            "Epoch 30/300\n",
            "80/80 [==============================] - 152s 2s/step - loss: 0.4371 - acc: 0.8004 - val_loss: 0.4847 - val_acc: 0.7958\n",
            "Epoch 31/300\n",
            "80/80 [==============================] - 149s 2s/step - loss: 0.4285 - acc: 0.8086 - val_loss: 0.4699 - val_acc: 0.8063\n",
            "Epoch 32/300\n",
            "80/80 [==============================] - 137s 2s/step - loss: 0.4181 - acc: 0.8145 - val_loss: 0.5240 - val_acc: 0.7719\n",
            "Epoch 33/300\n",
            "56/80 [====================>.........] - ETA: 33s - loss: 0.4163 - acc: 0.8097"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}