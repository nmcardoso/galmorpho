{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "splus_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Dfhn_xuMzlGv"
      ],
      "toc_visible": true,
      "mount_file_id": "1AZ581kRn-dsuPaP-9xt3ys9A5ZCXVaA1",
      "authorship_tag": "ABX9TyM9+BNxECKDwxA6dEEpfYeg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmcardoso/galmorpho/blob/master/splus_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vivABYTN239V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x \n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import multiprocessing as mp\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras import utils\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.applications import VGG16\n",
        "from progressbar import progressbar\n",
        "\n",
        "# !pip3 install git+https://github.com/nmcardoso/fitsbook-python\n",
        "# import fitsbook as fb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqLHp_vx9e2V",
        "colab_type": "code",
        "outputId": "567fea90-d326-4dd3-98e2-f9598acfaaf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Reprodutibilidade\n",
        "# https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = '12'\n",
        "np.random.seed(123)\n",
        "random.seed(1234)\n",
        "tf.set_random_seed(12345)\n",
        "\n",
        "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, \n",
        "#                               inter_op_parallelism_threads=1)\n",
        "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)\n",
        "\n",
        "print('Sementes Plantadas!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sementes Plantadas!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8IDVH7Pz1so",
        "colab_type": "text"
      },
      "source": [
        "## Preparação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2cNynjnqAWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/datasets/stamps_scaled_12ch_subset_64px.tar\" dataset.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faZlo4FERwdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/'My Drive'/datasets/stamps_scaled_12ch_subset_64px.csv /content/dataset.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH6fgV37vgyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbYRpllzlv7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -C dataset -xvf dataset.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKouK0TO1odD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NpySequence(utils.Sequence):\n",
        "  \"\"\"Generate data for Keras\"\"\"\n",
        "  def __init__(self, files, labels, classes, image_size=(256, 256), channels=3, batch_size=32, output_channels=3, channel_range=None):\n",
        "    self.files = files\n",
        "    self.labels = self.__to_categorical(labels, classes)\n",
        "    self.image_size = image_size\n",
        "    self.channels = channels\n",
        "    self.output_channels = output_channels\n",
        "    self.channel_range = channel_range\n",
        "    self.batch_size = batch_size\n",
        "    self.indexes = [i for i in range(len(files))]\n",
        "    np.random.shuffle(self.indexes)\n",
        "  \n",
        "  def __len__(self):\n",
        "    \"\"\"The number of batches per epoch\"\"\"\n",
        "    return int(np.floor(len(self.files) / self.batch_size))\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"Generate one batch of data\"\"\"\n",
        "    partition = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    X, Y = self.__data_generation(partition)\n",
        "    if self.channel_range:\n",
        "      return X[..., self.channel_range[0]:self.channel_range[1]], Y\n",
        "    elif self.channels > self.output_channels:\n",
        "      return [X[..., 0:3], X[..., 3:6], X[..., 6:9], X[..., 9:12]], Y\n",
        "    else:\n",
        "      return X, Y\n",
        "  \n",
        "  def on_epoch_end(self):\n",
        "    \"\"\"Shuffle files list and remap labels\"\"\"\n",
        "    np.random.shuffle(self.indexes)\n",
        "    \n",
        "  def __to_categorical(self, labels, classes):\n",
        "    \"\"\"Labels to numbers\"\"\"\n",
        "    classes_dict = {c:i for i,c in enumerate(classes)}\n",
        "    return [classes_dict[l] for l in labels]\n",
        "\n",
        "  def __data_generation(self, partition):\n",
        "    \"\"\"Load npy file and associate with a label\"\"\"\n",
        "    X = np.empty((self.batch_size, *self.image_size, self.channels))\n",
        "    Y = np.empty((self.batch_size,), dtype=int)\n",
        "\n",
        "    for i, index in enumerate(partition):\n",
        "      X[i,] = np.load(self.files[index])\n",
        "      Y[i] = self.labels[index]\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ4ZuEFRzlJG",
        "colab_type": "text"
      },
      "source": [
        "## Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfhn_xuMzlGv",
        "colab_type": "text"
      },
      "source": [
        "### Não usados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjJXg_UMzsSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
        "  # 1x1 conv\n",
        "  conv1 = layers.Conv2D(f1, (1, 1), padding='same', activation='relu')(layer_in)\n",
        "\n",
        "  # 3x3 conv\n",
        "  conv3 = layers.Conv2D(f2_in, (1, 1), padding='same', activation='relu')(layer_in)\n",
        "  conv3 = layers.Conv2D(f2_out, (3, 3), padding='same', activation='relu')(layer_in)\n",
        "\n",
        "  # 5x5 conv\n",
        "  conv5 = layers.Conv2D(f3_in, (1, 1), padding='same', activation='relu')(layer_in)\n",
        "  conv5 = layers.Conv2D(f3_out, (5, 5), padding='same', activation='relu')(conv5)\n",
        "\n",
        "  # 3x3 max pooling\n",
        "  pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(layer_in)\n",
        "  pool = layers.Conv2D(f4_out, (1, 1), padding='same', activation='relu')(pool)\n",
        "\n",
        "  # concatenate filters, assumes filters/channels last\n",
        "  layer_out = layers.concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
        "  return layer_out\n",
        "\n",
        "def compile_inception_model(image_size):\n",
        "  input_layer = layers.Input(shape=image_size + (3,))\n",
        "  conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "  pool1 = layers.MaxPool2D((2, 2))(conv1)\n",
        "  conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "  pool2 = layers.MaxPool2D((2, 2))(conv2)\n",
        "  iblock1 = inception_module(input_layer, 32, 48, 64, 8, 16, 16)\n",
        "  iblock2 = inception_module(iblock1, 64, 48, 96, 16, 48, 32)\n",
        "  flatten = layers.Flatten()(iblock2)\n",
        "  dense1 = layers.Dense(1024, activation='relu')(flatten)\n",
        "  dropout1 = layers.Dropout(.3)(dense1)\n",
        "  dense2 = layers.Dense(512, activation='relu')(dropout1)\n",
        "  dropout2 = layers.Dropout(.3)(dense2)\n",
        "  dense3 = layers.Dense(256, activation='relu')(dropout2)\n",
        "  dropout3 = layers.Dropout(.3)(dense3)\n",
        "  output = layers.Dense(1, activation='sigmoid')(dropout3)\n",
        "  model = models.Model(inputs=input_layer, outputs=output)\n",
        "  model.name = 'splus_inception'\n",
        "  utils.plot_model(model, to_file='model.png')\n",
        "  model.compile(optimizer=optimizers.RMSprop(lr=5e-5),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "def compile_inception_pretrained(image_size):\n",
        "  base_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "  x = base_model.output\n",
        "  x = layers.GlobalAveragePooling2D()(x)\n",
        "  x = layers.Dense(512, activation='relu')(x)\n",
        "  x = layers.Dropout(.5)(x)\n",
        "  x = layers.Dense(256, activation='relu')(x)\n",
        "  x = layers.Dropout(.5)(x)\n",
        "  output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = models.Model(inputs=base_model.input, outputs=output)\n",
        "  model.name = 'splus_inception_pretrained'\n",
        "\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  model.compile(optimizer=optimizers.RMSprop(lr=5e-5),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "def compile_VGG16(image_size):\n",
        "  model = models.Sequential()\n",
        "  model.name = 'splus_vgg16_impl'\n",
        "  model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(image_size + (3,))))\n",
        "  model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(2048, activation='relu'))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(1024, activation='relu'))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "def compile_multidim_model(image_size):\n",
        "  input_tensor = layers.Input(shape=image_size + (1,))\n",
        "\n",
        "  branch_outputs = []\n",
        "  for i in range(3):\n",
        "    out = layers.Lambda(lambda x: x[:, i])(input_tensor)\n",
        "    out = layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(image_size + (1,)))(out)\n",
        "    out = layers.MaxPooling2D((2, 2))(out)\n",
        "    out = layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(image_size + (1,)))(out)\n",
        "    out = layers.MaxPooling2D((2, 2))(out)\n",
        "    out = layers.Conv2D(128, (3, 3), activation='relu', padding='same', input_shape=(image_size + (1,)))(out)\n",
        "    out = layers.MaxPooling2D((2, 2))(out)\n",
        "    branch_outputs.append(out)\n",
        "  \n",
        "  x = layers.Concatenate()(branch_outputs)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(1024, activation='relu')(x)\n",
        "  x = layers.Dropout(.5)(x)\n",
        "  x = layers.Dense(512, activation='relu')(x)\n",
        "  x = layers.Dropout(.5)(x)\n",
        "  x = layers.Dense(256, activation='relu')(x)\n",
        "  x = layers.Dropout(.5)(x)\n",
        "  x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = models.Model(inputs=input_tensor, outputs=x)\n",
        "  model.name = 'splus_multidim_conv'\n",
        "  model.compile(optimizer=optimizers.RMSprop(lr=5e-5),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  utils.plot_model(model, to_file='model.png')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni3VnVz_zvzw",
        "colab_type": "text"
      },
      "source": [
        "### Usados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idKUoZkgSBzH",
        "colab_type": "code",
        "outputId": "29960a13-841a-498a-addb-785a8b0c786e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def compile_parallel_model(image_size, channels=3):\n",
        "  # inception_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=image_size + (3,))\n",
        "  # for layer in inception_model.layers:\n",
        "  #     layer.trainable = False\n",
        "\n",
        "  # input_layer = layers.Input(shape=image_size + (channels,))\n",
        "  branch_outputs = []\n",
        "  inputs = []\n",
        "  for i in range(int(channels / 3)):\n",
        "    # x = layers.Lambda(lambda t: t[..., (i * 3):(i * 3 + 2)])(input_layer)\n",
        "    # base_model = applications.InceptionV3(weights='imagenet', include_top=False, input_tensor=x)\n",
        "    # for layer in base_model.layers:\n",
        "    #   layer.trainable = False\n",
        "    # j = inception_model.output\n",
        "    # x = layers.GlobalAveragePooling2D()(j)\n",
        "    input_layer = layers.Input(shape=image_size + (3,), name=f'InputImage_{i + 1}')\n",
        "    inputs.append(input_layer)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', name=f'Conv2D_{i + 1}1')(input_layer)\n",
        "    x = layers.MaxPooling2D((2, 2), name=f'MaxPooling2D_{i + 1}1')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', name=f'Conv2D_{i + 1}2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=f'MaxPooling2D_{i + 1}2')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', name=f'Conv2D_{i + 1}3')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=f'MaxPooling2D_{i + 1}3')(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', name=f'Conv2D_{i + 1}4')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=f'MaxPooling2D_{i + 1}4')(x)\n",
        "    # x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "    # x = layers.MaxPooling2D((2, 2))(x)\n",
        "    branch_outputs.append(x)\n",
        "  x = layers.Concatenate(name='Mixer')(branch_outputs)\n",
        "  x = layers.Flatten(name='Flatten')(x)\n",
        "  # x = layers.Dense(2048, activation='relu')(x)\n",
        "  # x = layers.Dropout(.5)(x)\n",
        "  x = layers.Dense(2048, activation='relu', name='Dense_1')(x)\n",
        "  x = layers.Dropout(.5, name='Dropout_1')(x)\n",
        "  x = layers.Dense(1024, activation='relu', name='Dense_2')(x)\n",
        "  x = layers.Dropout(.5, name='Dropout_2')(x)\n",
        "  x = layers.Dense(1024, activation='relu', name='Dense_3')(x)\n",
        "  x = layers.Dropout(.5, name='Dropout_3')(x)\n",
        "  x = layers.Dense(512, activation='relu', name='Dense_4')(x)\n",
        "  x = layers.Dropout(.5, name='Dropout_4')(x)\n",
        "  x = layers.Dense(1, activation='sigmoid', name='Dense_5')(x)\n",
        "  model = models.Model(inputs=inputs, outputs=x)\n",
        "  model.name = 'multi_input_64'\n",
        "  model.compile(optimizer=optimizers.RMSprop(lr=6e-5),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  utils.plot_model(model, to_file='model.png')\n",
        "  return model\n",
        "compile_parallel_model((64, 64), 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7fb4f3d09828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ghBzSbF9fpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(channel_range=None):\n",
        "  global train_generator, test_generator, val_generator\n",
        "  df = pd.read_csv('/content/dataset.csv')\n",
        "  E = df[df.CLASS == 'E']\n",
        "  S = df[df.CLASS == 'S']\n",
        "\n",
        "  # train_df = pd.concat([E[0:3127], S[0:951]])\n",
        "  train_df = pd.concat([E[0:1400], S[0:1000]])\n",
        "  train_X = [f'/content/dataset/{f}.npy' for f in train_df.ID.tolist()]\n",
        "  train_Y = train_df.CLASS.tolist()\n",
        "\n",
        "  # val_df = pd.concat([E[3128:5004], S[952:1522]])\n",
        "  val_df = pd.concat([E[1401:2100], S[1001:1500]])\n",
        "  val_X = [f'/content/dataset/{f}.npy' for f in val_df.ID.tolist()]\n",
        "  val_Y = val_df.CLASS.tolist()\n",
        "\n",
        "  # test_df = pd.concat([E[5005:], S[1523:]])\n",
        "  test_df = pd.concat([E[2101:], S[1501:]])\n",
        "  test_X = [f'/content/dataset/{f}.npy' for f in test_df.ID.tolist()]\n",
        "  test_Y = test_df.CLASS.tolist()\n",
        "\n",
        "  train_generator = NpySequence(train_X, train_Y, ['E', 'S'], image_size=(64, 64), channels=12, batch_size=20, output_channels=3)\n",
        "  val_generator = NpySequence(val_X, val_Y, ['E', 'S'], image_size=(64, 64), channels=12, batch_size=20, output_channels=3)\n",
        "  test_generator = NpySequence(test_X, test_Y, ['E', 'S'], image_size=(64, 64), channels=12, batch_size=20, output_channels=3)\n",
        "\n",
        "def compile_model(image_size):\n",
        "  model = models.Sequential()\n",
        "  model.name = 'splus_convolutional'\n",
        "  model.add(layers.Conv2D(1024, (3, 3), activation='relu', input_shape=(image_size + (12,))))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(2048, activation='relu'))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(1024, activation='relu'))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dropout(.5))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer=optimizers.RMSprop(lr=5e-4),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  return model\n",
        "\n",
        "def fit(model, epochs=1, workers=1):\n",
        "  global history, train_generator, val_generator\n",
        "  use_mp = workers > 1\n",
        "  history = model.fit_generator(\n",
        "      train_generator,\n",
        "      # steps_per_epoch=80,\n",
        "      # validation_steps=30,\n",
        "      epochs=epochs,\n",
        "      validation_data=val_generator,\n",
        "      callbacks=[fb.callbacks.FitsbookCallback()],\n",
        "      use_multiprocessing=use_mp,\n",
        "      workers=workers\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KycSijHPtc_V",
        "colab_type": "text"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm3MY-kw29F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess()\n",
        "m = compile_parallel_model((64, 64), 12)\n",
        "fit(m, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}